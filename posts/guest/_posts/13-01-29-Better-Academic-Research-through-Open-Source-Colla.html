---
title: "Better Academic Research through Open Source Collaboration, a guest post by Ross Gardler"
alias: /Blogs/EntryId/82/Better-Academic-Research-through-Open-Source-Collaboration-a-guest-post-by-Ross-Gardler
---
<p>Academic researchers succeed or fail based on their publishing record. Publications are intended to communicate their findings and enable others to build upon their work. <a href="http://en.wikipedia.org/wiki/Reproducibility#Reproducible_research">Reproducibility of scientific research</a> is a fundamental part of publication. In this post I argue that open source software not only provides a way of ensuring reproducibility in many research projects but it also allows researchers to accelerate the research process through a collaborative sharing and development of research software. I will also begin to look at how researchers can engage with open source without compromising their position as leaders in their field.</p>
<h2>Why don't many researchers publish software code?</h2>
<p>Researchers are accustomed to publishing their findings in peer reviewed journals. In fact, academic research careers are built on publication records. It is therefore reasonable to expect that open source publication would be attractive to most researchers. This expectation can come, for example, from the Open Source Initiative <a href="http://opensource.org/osd">definition of open source</a> as "a development method for software that harnesses the power of distributed peer review and transparency of process."</p>
<p>Unfortunately this is not the case, academic peer review is a tightly controlled and restricted model whereas open source peer review is wide open and unrestricted. The differences between academic peer review and open source peer review is one of the core reasons for <a href="http://lemire.me/blog/archives/2010/02/10/open-sourcing-your-software-hurts-your-competitiveness-as-a-researcher/">researchers reluctance to publish open source code</a>. Even when research code is published we rarely see any true collaboration around that code as we would expect for a viable open source community project.</p>
<p>Academic peer review models focus on the work of the individual rather than the collective. Each publication needs to be seen as a new work. Researchers will cite previous work as justification an background for their own assumptions, but they do not incrementally extend existing experiments in the way a community led open source project grows through small contributions. This focus on publication of complete and unique works means that researchers usually withhold interim results until the final research is ready for publication. This is driven, in part, by a fear that other researchers will leap ahead and publish first. Consequently, researchers who work with open source code will typically fork it and work independently rather than engage with the projects community.</p>
<p>A failure to be first to publish results in a loss of potential peer recognition which in turn results in a significant impact on future funding and employment opportunities. At best, a researcher will typically release code to support a published paper at the time of publication, rather than release in incremental steps. This is core to the problem facing academic researchers who wish to produce or engage with open source software. When such code is finally released it is likely to be a considerable amount of work with a highly specialised objective. It is so specialised that it is unlikely to attract significant contributions. Furthermore, where the work builds on existing open source solutions, it is likely to be seen as a "code dump" (a significant chunk of work rather than a set of incremental changes working towards a defined goal). Most community projects are resistant to code dumps because they are usually hard to review and difficult to maintain.</p>
<p>This fear of a lack of maintenance is further justified by the fact that most academic researchers are not interested in long term maintenance of their code. They are often more interested in the short term goals of their research work. That is, they receive a grant, typically for 12-48 months, which allows them to seek an answer to a specific question. Once this work is delivered and peer reviewed they move on to the next problem (and thus the next grant). Any software solution that is defined as part of their research is typically a specific solution for a specific, tightly bounded, task.</p>
<p>These highly specialised software solutions are not rarely engineered for reuse. They are often hacks to answer a specific question quickly. The "quick hack" nature of academic research software further contributes to the lack of maintainability and reusability. Consequently, it is often of little interest to third parties unless they happen to be working on a problem that is closely related to the original problem.</p>
<h2>Research software is no different to any other software</h2>
<p>What many academic researchers fail to understand is that this specialisation problem is not unique to research projects. Most software developers will seek to provide an adequate solution to their specific problem, as quickly as possible. They don't seek to build a perfect, all-purpose, tool set that can be reused in every conceivable circumstance. They simply solve the problem at hand and move on to the next one.</p>
<p>The difference is that open source developers will do this incremental problem solving using shared code. They will share that code in incremental steps rather than wait until they've built the complete system they need but is too specific for others to use. Other people will reuse and improve on the initial solution, perhaps generalising it a little in the process. There is no need to share the details of why one needs a "green widget" nor is there any reason to prevent someone modifying it so it can be either a "green widget" or a "blue widget".</p>
<p>This early sharing and iterative development is not unique to open source software. In fact this process embodies four of the twelve <a href="http://agilemanifesto.org/principles.html">core principles of the Agile Manifesto</a>. Specifically:
</p>
<ul>
    <li>Satisfy the customer through early and continuous delivery of valuable software.</li>
    <li>Deliver working software frequently.</li>
    <li>Simplicity -- the art of maximizing the amount of work not done -- is essential.</li>
    <li>Welcome changing requirements, even late in development.</li>
</ul>
<h2>Open source the ingredients, not the meal</h2>
<p>The trick to successful open source collaboration is not to deliver complete systems but to look at components that can be usefully reused in different situations. Consider, for example, software for working with DNA samples in some way. Such software is highly specialised. It is tempting to look for other people who are working in the same area and seek to share code with them. Whilst this can be very fruitful it does limit the potential community to those working in a niche area (some of whom may be "competing" researchers). However, consider that processing DNA samples is, in many ways the same as processing other data. We have storage demands, scalability issues, visualisation needs and so on. If we look at each of these items separately we can see much greater potential for collaboration.</p>
<p>The majority of successful open source projects are components rather than complete systems. Even products that are complete in their own right, such as the Mozilla Firefox web browser or the Apache OpenOffice suite of productivity tools, provide extensive mechanisms for customising the base install through individual components (plugins) to match specific needs.</p>
<p>I expanded on this general concept in <a href="http://blogs.computerworlduk.com/apache-asserts/2011/10/increasing-your-rate-of-innovation/index.htm">"Twitter, open source, DNA and bread making"</a> last year. In that post I concluded that "Chemists tell us that increasing the surface area of a material in a chemical process will result in a faster and more complete reaction. It's no different in open source software. By ensuring that you break your systems into smaller components and collaborate on those components rather than the whole system you will increase the number of contact points between yourself and others. The end result is faster and more complete innovation processes." What I don't cover in that article is the fact that by separating the system into separate components third parties are unaware of your ultimate objective. Consequently your research agenda remains hidden until you are ready to publish the final results, complete with a configuration of software components that provide a complete solution for reproducing the results.</p>
<p>Furthermore, this faster pace of innovation (or perhaps invention in the case of original research) will result in more publication opportunities. This means more recognition in the traditional academic peer review process. We are already seeing this happen here in the Outercurve Foundation through our <a href="/Galleries/ResearchAccelerators">Research Accelerator Gallery</a> where experienced academic researchers are on hand to help guide academics in their pursuit of accelerated research discoveries through open source development models.</p>
